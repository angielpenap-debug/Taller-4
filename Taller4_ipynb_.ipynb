{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAypvSpfr5oM+iazeYrrDw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angielpenap-debug/Taller-4/blob/main/Taller4_ipynb_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problemas de exactitud y error Preguntas cortas:**\n",
        "\n",
        "1. Entrenas un modelo y obtienes un 99% de exactitud sobre los datos de entrenamiento, pero solo un 75% sobre los datos de prueba. ¿Qué problema indica este resultado y por qué?\n",
        "\n",
        "Respuesta 1: Es SOBREAJUSTE, El modelo aprendio demasiado bien los datos de entrenamiento, pero cuando se enfrenta a datos nuevos, no logra generalizar y su rendimiento baja bastante.\n",
        "\n",
        "2. Si el error de tu modelo es muy alto tanto en el conjunto de entrenamiento como en el de validación, ¿cuál es el problema más probable? ¿Creerías que añadir más datos de entrenamiento solucionaría el problema?\n",
        "\n",
        "Respuesta 2: Esto indica SUBAJUSTE, el modelo no esta aprendiendo lo suficiente de los datos, por lo que añadir mas datos no ayuda; se necesita un modelo mas complejo o nueva variable.\n",
        "\n",
        "3. En un problema para predecir fallas en una máquina, tienes 100 variables provenientes de sensores, pero sospechas que solo unas pocas son realmente importantes. ¿Usarías Ridge o Lasso? Justifica tu respuesta.\n",
        "\n",
        "Respuesta 3: Usaria LSSO, no solo penaliza coeficientes grandes, sino ademas lleva algunos coeficientes exactamente a cero, haciendo una selección automática de variables.\n",
        "\n",
        "4. Si entrenas un modelo Lasso y aumentas gradualmente el valor del hiperparámetro de penalización (λ), ¿qué efecto esperarías observar en los coeficientes del modelo?\n",
        "\n",
        "Respuesta 4: A medida de que λ aumenta, los coeficientes se reducen de tamaño porque la penalización los lleva hacia cero.\n",
        "\n",
        "5. Al ejecutar el código de regularización 3D, ¿qué sucede con los coeficientes del modelo a medida que aumenta el valor de λ? ¿Qué interpretación le das a la forma diferente en que Ridge y Lasso aplican sus penalizaciones?\n",
        "\n",
        "Respuesta5 5 : Ambos reducen coeficientes al aumentar λ, pero:\n",
        "\n",
        "Ridge nunca los hace cero.\n",
        "Lasso puede llevarlos a cero.\n",
        "Esto refleja cómo Lasso selecciona variables y Ridge solo suaviza.\n",
        "\n",
        "6. Quieres optimizar un modelo Ridge y pruebas manualmente alpha=10, obteniendo un buen resultado. ¿Por qué sigue siendo metodológicamente superior usar GridSearchCV en lugar de quedarte con ese valor?\n",
        "\n",
        "Respuesta 6: Porque GridSearchCV evalúa múltiples valores de forma objetiva con validación cruzada, garantizando el mejor rendimiento\n",
        "\n",
        "7.  Además del modelo en sí (ej. Lasso()), ¿cuáles son los dos componentes principales que debes proporcionar a GridSearchCV para iniciar la búsqueda de hiperparámetros?\n",
        "\n",
        "Respuesta 7: Los dos componentes claves son:\n",
        "              * La parrilla de hiperparámetros (param_grid).\n",
        "              * La métrica de evaluación (scoring).\n",
        "\n",
        "8. Si GridSearchCV selecciona un alpha muy pequeño (cercano a cero) como el mejor parámetro para tu modelo, ¿qué te sugiere esto sobre el nivel de sobreajuste que tenía tu modelo original sin regularizar?    \n",
        "\n",
        "Respuesta 8: El modelo no estaba sufriendo un sobreajuste.Por lo que no requiere pealización fuerte, pues generaliza bien sin regularización.\n",
        "\n",
        "\n",
        "9. En un árbol de decisión para optimizar la logística de un almacén, ¿qué podría representar un nodo hoja?\n",
        "\n",
        "Respuesta 9: Puede representar\n",
        "            * Clasificación de un pedido (Pedido urgente- Pedido estandar)\n",
        "            * Preparación (Despacho inmediato - Despacho programado)\n",
        "            * Demanda (Alta - Baja)\n",
        "\n",
        "10. Un ingeniero crea un árbol para predecir fallos en una máquina. El árbol es extremadamente profundo y tiene reglas muy específicas como \"Si la temperatura es 75.3°C y la vibración es 0.152 m/s² y el operador es Juan...\". ¿Qué problema de ajuste es este y por qué no sería fiable en la práctica diaria de la planta?        \n",
        "\n",
        "Respuesta 10:  Es sobreajuste: el árbol memoriza casos específicos y pierde capacidad de generalizar, volviéndose poco fiable con nuevos datos.\n",
        "\n",
        "11. Al visualizar la \"importancia de las características\" de tu árbol, descubres que el \"proveedor de materia prima\" es la variable más importante. ¿Qué acción inmediata podrías tomar en la planta con esta información?\n",
        "\n",
        "Respuesta 11: Realizar una auditoría o mejora con el proveedor, revisando su calidad o cambiando a otro proveedor para reducir defectos.\n",
        "\n",
        "12. Si tu árbol de decisión está clasificando perfectamente los datos históricos pero falla mucho con los datos de la última semana (sobreajuste), ¿qué parámetro de poda ajustarías primero para que generalice mejor?\n",
        "\n",
        "Respuesta 12: Ajustar max_depth (profundidad máxima) o min_samples_leaf, para limitar la complejidad y mejorar la generalización.\n",
        "\n"
      ],
      "metadata": {
        "id": "-u7WsniBe365"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8MLeuO2KfI35"
      }
    }
  ]
}